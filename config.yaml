# --- Dataset Configuration ---
data_dir: '/kaggle/input/datn-cell/Our_Plasmodium_Classification_Khanh_Thesis_Jan2025/' # Base dir for relative paths if needed

# --- Datasets Configuration (List) ---
datasets:
  - type: 'annotation' # First dataset definition (e.g., SMOTE for training)
    # Settings for 'annotation' type
    annotation_train: '/kaggle/input/datn-smote/smote_synthesized_output/synthesized_annotations.txt'
    annotation_val: '/kaggle/input/datn-cell/Our_Plasmodium_Classification_Khanh_Thesis_Jan2025/val_annotation.txt' # Use original val
    annotation_test: '/kaggle/input/datn-cell/Our_Plasmodium_Classification_Khanh_Thesis_Jan2025/test_annotation.txt' # Use original test
    annotation_root: '/kaggle/input/datn-smote/smote_synthesized_output' # Root for THIS dataset's images
    # If val/test annotations use different root, specify explicitly or adjust AnnotationDataset
    # annotation_val_root: '/kaggle/input/datn-cell/Our_Plasmodium_Classification_Khanh_Thesis_Jan2025/cropped_RBCs'
    # annotation_test_root: '/kaggle/input/datn-cell/Our_Plasmodium_Classification_Khanh_Thesis_Jan2025/cropped_RBCs'

  - type: 'annotation' # Optional: Second dataset definition (e.g., original training data)
    annotation_train: '/kaggle/input/datn-cell/Our_Plasmodium_Classification_Khanh_Thesis_Jan2025/train_annotation.txt'
    annotation_val: null # Can be null if val/test are taken from the first dataset
    annotation_test: null
    annotation_root: '/kaggle/input/datn-cell/Our_Plasmodium_Classification_Khanh_Thesis_Jan2025/cropped_RBCs'

  # - type: 'imagefolder' # Optional: Example ImageFolder definition
  #   imagefolder_root: '/path/to/cifar10_like_data'
  #   imagefolder_train_subdir: 'train'
  #   imagefolder_val_subdir: 'val'
  #   imagefolder_test_subdir: 'test'

batch_size: 32
num_workers: 2 # Adjusted based on typical Kaggle limits

# --- Class Configuration ---
class_names:
  - "Ring"
  - "Trophozoite"
  - "Schizont"
  - "Gametocyte" # Corrected spelling
  - "Healthy RBC"
  - "Other"

# --- Model Configuration ---
model_names:
  # - mobilenetv4_hybrid_large.e600_r384_in1k # Example timm model
  # - resnet50 # Example torchvision model
  - mobilenet_v3

# --- Training Configuration ---
training:
  num_epochs: 100 # Reduced for example
  patience: 20   # Early stopping patience
  use_amp: false # Use Automatic Mixed Precision (requires CUDA)
  clip_grad_norm: 0 # Max norm for gradient clipping (set to 0 or null to disable)
  train_ratio: 1 # Ratio of the (combined) training set to use (1.0 = 100%, 0.1 = 10%)

# --- Optimizer Configuration ---
optimizer:
  type: AdamW # Options: Adam, AdamW, SGD, etc.
  lr: 1e-4    # Learning Rate moved here
  params: # Parameters specific to the optimizer type
    weight_decay: 0.01 # Example for AdamW

# --- LR Scheduler Configuration ---
scheduler:
  type: CosineAnnealingLR # Options: StepLR, ReduceLROnPlateau, CosineAnnealingLR, etc.
  T_max: 100 # For CosineAnnealingLR: Maximum number of iterations (set to num_epochs)
  eta_min: 1e-6 # For CosineAnnealingLR: Minimum learning rate

# --- Loss Function (Criterion) Configuration ---
criterion: CrossEntropyLoss # Options: CrossEntropyLoss, FocalLoss, F1Loss
criterion_params: # Parameters specific to the criterion
  # For FocalLoss:
  # gamma: 2.0
  # reduction: 'mean'
  # For F1Loss:
  # beta: 1.0
  # epsilon: 1e-7
  # For CrossEntropyLoss:
  use_class_weights: false # Set to true to compute and use class weights

# --- Results Directory ---
results_dir: 'results_kaggle' # Separate results dir for Kaggle runs

# --- Device Configuration ---
device:
  use_cuda: true      # Attempt to use CUDA (GPU) if available
  multi_gpu: true     # Attempt to use DataParallel if multiple GPUs detected
